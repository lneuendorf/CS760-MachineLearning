{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609d0e5c",
   "metadata": {},
   "source": [
    "# CS760 HW4 - Naive Bayes\n",
    "# By: Luke Neuendorf\n",
    "***\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b1cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10000) \n",
    "pd.set_option('display.max_columns', 10000) \n",
    "import string\n",
    "import NaiveBayes\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eac1f5",
   "metadata": {},
   "source": [
    "***\n",
    "## Problem 1\n",
    "Use files 0.txt to 9.txt in each language as the training data. Estimate the prior probabilities $\\hat{p}(y = e)$, $\\hat{p}(y = j)$, $\\hat{p}(y = s)$ using additive smoothing with parameter $\\frac{1}{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f8374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bagOfCharacters(file_list=[]):\n",
    "    acceptable_chars = list(string.ascii_lowercase)\n",
    "    acceptable_chars.extend(\" \")\n",
    "    data = []\n",
    "    \n",
    "    # count the total occurences of each token (letters+space) in each file\n",
    "    for i in range(0,len(file_list)):\n",
    "        char_list =[]\n",
    "        with open('data/'+file_list[i]+'.txt', 'r') as file:\n",
    "            file_contents = file.read()\n",
    "            char_list = list(file_contents)\n",
    "        data.append(dict())\n",
    "        data[i]['x'] = [char for char in char_list if char in acceptable_chars]\n",
    "        data[i]['y'] = file_list[i][0]\n",
    "        data[i]['numchars'] = len(data[i]['x'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0cb338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_list = ['e0','e1','e2','e3','e4','e5','e6','e7','e8','e9',\n",
    "                      's0','s1','s2','s3','s4','s5','s6','s7','s8','s9',\n",
    "                      'j0','j1','j2','j3','j4','j5','j6','j7','j8','j9']\n",
    "train_data = get_bagOfCharacters(training_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6681eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = list(string.ascii_lowercase)\n",
    "characters.extend(\" \")\n",
    "languages = ['e','s','j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a6129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes.NaiveBayesClassifier()\n",
    "model.train(train_data, characters, languages, alpha=.5, K_L=3, K_S=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8252b65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_hat(y=language): {'e': 0.3333333333333333, 's': 0.3333333333333333, 'j': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "print(\"p_hat(y=language):\", model.get_prior_pr_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04149f12",
   "metadata": {},
   "source": [
    "***\n",
    "## Problem 2\n",
    "Using the same training data, estimate the class conditional probability (multinomial parameter) for English\n",
    "$θ_{i,e}\\;:=\\;\\hat{p}(c_i |y=e)$\n",
    "where $c_i$ is the i-th character. That is, $c_1$ = a, . . . , $c_{26}$ = z, $c_{27}$ = space. Again, use additive smoothing with parameter $\\frac{1}{2}$. Give the formula for additive smoothing with parameter $\\frac{1}{2}$ in this case. Print $θ_e$ which is a vector with 27 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45430ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "θ_e:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 0.0601685114819098,\n",
       " 'b': 0.011134974392863043,\n",
       " 'c': 0.021509995043779945,\n",
       " 'd': 0.021972575582355856,\n",
       " 'e': 0.1053692383941847,\n",
       " 'f': 0.018932760614571286,\n",
       " 'g': 0.017478936064761277,\n",
       " 'h': 0.047216256401784236,\n",
       " 'i': 0.055410540227986124,\n",
       " 'j': 0.001420783082768875,\n",
       " 'k': 0.0037336857756484387,\n",
       " 'l': 0.028977366595076822,\n",
       " 'm': 0.020518751032545846,\n",
       " 'n': 0.057921691723112505,\n",
       " 'o': 0.06446390219725756,\n",
       " 'p': 0.01675202378985627,\n",
       " 'q': 0.0005617049396993227,\n",
       " 'r': 0.053824549810011564,\n",
       " 's': 0.06618205848339666,\n",
       " 't': 0.08012555757475633,\n",
       " 'u': 0.026664463902197257,\n",
       " 'v': 0.009284652238559392,\n",
       " 'w': 0.015496448042293078,\n",
       " 'x': 0.001156451346439782,\n",
       " 'y': 0.013844374690236246,\n",
       " 'z': 0.0006277878737815959,\n",
       " ' ': 0.1792499586981662}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"θ_e:\")\n",
    "model.get_conditional_pr_dict()['e']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6d438",
   "metadata": {},
   "source": [
    "***\n",
    "## Problem 3\n",
    "Print $θ_j$, $θ_s$, the class conditional probabilities for Japanese and Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59eaefcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "θ_j:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 0.1317656102589189,\n",
       " 'b': 0.010866906600510151,\n",
       " 'c': 0.005485866033054963,\n",
       " 'd': 0.01722631818022992,\n",
       " 'e': 0.06020475907613823,\n",
       " 'f': 0.003878542227191726,\n",
       " 'g': 0.014011670568503443,\n",
       " 'h': 0.03176211607673224,\n",
       " 'i': 0.09703343932352633,\n",
       " 'j': 0.0023411020650616725,\n",
       " 'k': 0.05740941332681086,\n",
       " 'l': 0.001432614696530277,\n",
       " 'm': 0.03979873510604843,\n",
       " 'n': 0.05671057688947902,\n",
       " 'o': 0.09116321324993885,\n",
       " 'p': 0.0008735455466648031,\n",
       " 'q': 0.00010482546559977637,\n",
       " 'r': 0.04280373178657535,\n",
       " 's': 0.0421747789929767,\n",
       " 't': 0.056990111464411755,\n",
       " 'u': 0.07061742199238269,\n",
       " 'v': 0.0002445927530661449,\n",
       " 'w': 0.01974212935462455,\n",
       " 'x': 3.4941821866592126e-05,\n",
       " 'y': 0.01415143785596981,\n",
       " 'z': 0.00772214263251686,\n",
       " ' ': 0.12344945665466997}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"θ_j:\")\n",
    "model.get_conditional_pr_dict()['j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e2d7ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "θ_s:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 0.10456045141993771,\n",
       " 'b': 0.008232863618143134,\n",
       " 'c': 0.03752582405722919,\n",
       " 'd': 0.039745922111559924,\n",
       " 'e': 0.1138108599796491,\n",
       " 'f': 0.00860287996053159,\n",
       " 'g': 0.0071844839813758445,\n",
       " 'h': 0.0045327001942585795,\n",
       " 'i': 0.049859702136844375,\n",
       " 'j': 0.006629459467793161,\n",
       " 'k': 0.0002775122567913416,\n",
       " 'l': 0.052943171656748174,\n",
       " 'm': 0.02580863988159477,\n",
       " 'n': 0.054176559464709693,\n",
       " 'o': 0.07249236841293824,\n",
       " 'p': 0.02426690512164287,\n",
       " 'q': 0.007677839104560451,\n",
       " 'r': 0.05929511886774999,\n",
       " 's': 0.06577040485954797,\n",
       " 't': 0.03561407295488884,\n",
       " 'u': 0.03370232185254849,\n",
       " 'v': 0.00588942678301625,\n",
       " 'w': 9.250408559711388e-05,\n",
       " 'x': 0.0024976103111220747,\n",
       " 'y': 0.007862847275754679,\n",
       " 'z': 0.0026826184823163022,\n",
       " ' ': 0.16826493170115014}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"θ_s:\")\n",
    "model.get_conditional_pr_dict()['s']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a876c",
   "metadata": {},
   "source": [
    "***\n",
    "## Problem 4\n",
    "Treat e10.txt as a test document x. Represent x as a bag-of-words count vector (Hint: the vocabulary has\n",
    "size 27). Print the bag-of-words vector x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a405fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bagOfCharactersCount(file):\n",
    "    accepted_chars = list(string.ascii_lowercase)\n",
    "    accepted_chars.extend(\" \")\n",
    "    bag_of_char_count = dict()\n",
    "    \n",
    "    char_list =[]\n",
    "    with open('data/'+file+'.txt', 'r') as file:\n",
    "        file_contents = file.read()\n",
    "        char_list = list(file_contents)\n",
    "    num_chars = Counter(char_list)\n",
    "    for char in accepted_chars:\n",
    "        bag_of_char_count[char] = num_chars[char]\n",
    "    \n",
    "    return bag_of_char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fbe0bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 164,\n",
       " 'b': 32,\n",
       " 'c': 53,\n",
       " 'd': 57,\n",
       " 'e': 311,\n",
       " 'f': 55,\n",
       " 'g': 51,\n",
       " 'h': 140,\n",
       " 'i': 140,\n",
       " 'j': 3,\n",
       " 'k': 6,\n",
       " 'l': 85,\n",
       " 'm': 64,\n",
       " 'n': 139,\n",
       " 'o': 182,\n",
       " 'p': 53,\n",
       " 'q': 3,\n",
       " 'r': 141,\n",
       " 's': 186,\n",
       " 't': 225,\n",
       " 'u': 65,\n",
       " 'v': 31,\n",
       " 'w': 47,\n",
       " 'x': 4,\n",
       " 'y': 38,\n",
       " 'z': 2,\n",
       " ' ': 498}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e10_bagOfCharactersCount = get_bagOfCharactersCount('e10')\n",
    "e10_bagOfCharactersCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e7c1f0",
   "metadata": {},
   "source": [
    "***\n",
    "## Problem 5\n",
    "For the x of e10.txt, compute $\\hat{p}(x | y)$ for y = e, j, s under the multinomial model assumption, respectively. Use the formula $\\hat{p}(x | y) = \\prod_{i=1}^{d}(θ_{i,y})^{x_i}$ \n",
    "where $x = (x_1,...,x_d)$. Show the three values: $\\hat{p}(x | y = e)$, $\\hat{p}(x | y = j)$, $\\hat{p}(x | y = s)$.\n",
    "Hint: you may notice that we omitted the multinomial coefficient. This is ok for classification because it is a constant w.r.t. y. Also, store all probabilities here and below in log() internally to avoid underflow. This also means you need to do arithmetic in log space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5db2d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted conditional probabilities of x:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'e': -7841.865447060635, 's': -8467.282044010557, 'j': -8771.433079075032}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Predicted conditional probabilities of x:\")\n",
    "model.predict(e10_bagOfCharactersCount)\n",
    "model.get_log_pred_conditional_pr_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50caa3f8",
   "metadata": {},
   "source": [
    "***\n",
    "## Problem 6\n",
    "For the x of e10.txt, use the Bayes rule and your estimated prior and likelihood, compute the posterior $\\hat{p}(y | x)$. Show the three values: $\\hat{p}(y = e | x)$, $\\hat{p}(y = j | x)$, $\\hat{p}(y = s | x)$). Show the predicted class label of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8fa3f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted posterior probabilites of x:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'e': -7842.964059349303, 's': -8468.380656299225, 'j': -8772.5316913637}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Predicted posterior probabilites of x:\")\n",
    "model.get_log_pred_posterior_pr_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0cbc4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label of x: e\n"
     ]
    }
   ],
   "source": [
    "print('Predicted class label of x:', model.predict(e10_bagOfCharactersCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278db5a",
   "metadata": {},
   "source": [
    "***\n",
    "## Problem 7\n",
    "Evaluate the performance of your classifier on the test set (files 10.txt to 19.txt in three languages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c9dcbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for e10: e\n",
      "Prediction for e11: e\n",
      "Prediction for e12: e\n",
      "Prediction for e13: e\n",
      "Prediction for e14: e\n",
      "Prediction for e15: e\n",
      "Prediction for e16: e\n",
      "Prediction for e17: e\n",
      "Prediction for e18: e\n",
      "Prediction for e19: e\n",
      "Prediction for s10: s\n",
      "Prediction for s11: s\n",
      "Prediction for s12: s\n",
      "Prediction for s13: s\n",
      "Prediction for s14: s\n",
      "Prediction for s15: s\n",
      "Prediction for s16: s\n",
      "Prediction for s17: s\n",
      "Prediction for s18: s\n",
      "Prediction for s19: s\n",
      "Prediction for j10: j\n",
      "Prediction for j11: j\n",
      "Prediction for j12: j\n",
      "Prediction for j13: j\n",
      "Prediction for j14: j\n",
      "Prediction for j15: j\n",
      "Prediction for j16: j\n",
      "Prediction for j17: j\n",
      "Prediction for j18: j\n",
      "Prediction for j19: j\n"
     ]
    }
   ],
   "source": [
    "test_file_list = ['e10','e11','e12','e13','e14','e15','e16','e17','e18','e19',\n",
    "                  's10','s11','s12','s13','s14','s15','s16','s17','s18','s19',\n",
    "                  'j10','j11','j12','j13','j14','j15','j16','j17','j18','j19']\n",
    "\n",
    "for file in test_file_list:\n",
    "    bagOfCharactersCount = get_bagOfCharactersCount(file)\n",
    "    print(\"Prediction for \", file,\": \", model.predict(bagOfCharactersCount),sep=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e4338",
   "metadata": {},
   "source": [
    "***\n",
    "## Problem 8\n",
    "Take a test document. Arbitrarily shuffle the order of its characters so that the words (and spaces) are scrambled beyond human recognition. How does this shuffling affect your Naive Bayes classifier’s prediction on this document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cffdde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File character counts match!\n"
     ]
    }
   ],
   "source": [
    "j0_shuffled_bagOfCharactersCount = get_bagOfCharactersCount('j0_shuffled')\n",
    "j0_bagOfCharactersCount = get_bagOfCharactersCount('j0')\n",
    "entered = False\n",
    "for char in list(j0_bagOfCharactersCount.keys()):\n",
    "    if j0_shuffled_bagOfCharactersCount[char] != j0_bagOfCharactersCount[char]:\n",
    "        print(\"ERROR: character counts between shuffled and not shuffled files don't match.\")\n",
    "        entered = True\n",
    "if ~entered:\n",
    "    print(\"File character counts match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adc646ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for j0: j\n",
      "Prediction for j0_shuffled: j\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction for j0: \", model.predict(j0_bagOfCharactersCount),sep=\"\")\n",
    "print(\"Prediction for j0_shuffled: \", model.predict(j0_shuffled_bagOfCharactersCount),sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7233c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted posterior probabilites of j0:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'e': -4213.009416088309, 's': -4568.17154055695, 'j': -3799.777414208914}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(j0_bagOfCharactersCount)\n",
    "print(\"Predicted posterior probabilites of j0:\")\n",
    "model.get_log_pred_posterior_pr_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0498ba3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted posterior probabilites of j0_shuffled:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'e': -4213.009416088309, 's': -4568.17154055695, 'j': -3799.777414208914}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(j0_shuffled_bagOfCharactersCount)\n",
    "print(\"Predicted posterior probabilites of j0_shuffled:\")\n",
    "model.get_log_pred_posterior_pr_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
